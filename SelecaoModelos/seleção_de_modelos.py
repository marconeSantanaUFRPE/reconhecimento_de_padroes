# -*- coding: utf-8 -*-
"""Seleção de modelos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eBT_or3vXTin8Z7ZG7UekqSWQuhLmk6P

**Imports e leitura do conjunto de dados**
"""

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score, classification_report, precision_recall_curve, auc, precision_score, recall_score, plot_precision_recall_curve
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectFromModel
from scipy.stats import randint, uniform, expon
import matplotlib.pyplot as plt
import pandas as pd


'''Carregando o conjunto de dados. Isto pode ser a leitura de um arquivo'''
baseDados = pd.read_csv('csv/dataframe.csv')
y = baseDados['classe']
del baseDados['id']
del baseDados['classe']
del baseDados['tempoGasto']
del baseDados['totalsub']
X = baseDados
print(X)


"""**Divisão do conjunto em treinamento e teste (Holdout com 20% para teste)**"""

'''Dividindo conjunto original em treinamento e teste'''
# a semente aleatória garante os mesmos conjuntos em toda execução
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=99) 
print('Dimensões dos conjuntos')
print(X_train.shape)
print(X_test.shape)

"""**Preprocessamento e seleção de atributos com filtro (árvore de decisão)**"""

''' Preprocessamento - Padronizando '''
# Aqui vamos só padronizar os dados (z-score). Poderíamos escalonar em [0,1] também
# Esta base ja vem escalonada, mas a gente vai fazer isso soh pra mostrar como se faz
padronizador = StandardScaler()
# O codigo comentado abaixo seria para executar a padronizacao FORA de pipeline
# meu_conjunto_completo_X = padronizador.fit_transform(meu_conjunto_completo_X)

'''Preprocessamento - Seleção de atributos com um wrapper'''
# Este seleçãão de atributos pode ser otimizada via seleçãão de modelos
# inserindo-a em um Pipeline
graduador = DecisionTreeClassifier() # 
selecionador = SelectFromModel(estimator=graduador)
# O codigo comentado abaixo seria para executar a selecao FORA de pipeline
# selecionador.fit(X_train, y_train) # Não posso usar o conjunto de teste para selecionar
# X_train = selecionador.transform(X_train)
# X_test = selecionador.transform(X_test) # Mas devo retirar os atributos descartados do conj de testes

'''Isto aqui pode ser um filtro, basta usar SelectKBest'''

"""**PCA**"""

'''Preprocessamento - Extração de características com PCA'''
# Por convensão, queremos ficar com as componentes que explicam 95% da variância,
# mas vou considerar essa variâância como hiperparâmetro a ser otimizado apenas por
# didática - para mostrar um pipeline mais longo 
pca = PCA()

"""**Instanciando classificador**"""

'''Instanciando o classificador. Para fazer todos os classificadores de uma vez, você
pode fazer uma lista de pipelines de classificadores e percorrê-la'''
classificador = MLPClassifier(early_stopping=True, validation_fraction=0.1)

"""**Seleção de modelos com Pipeline e Randomized search**"""

# Esta lista conterá a sequencia de métodos do pipeline terminando com o classificador
etapas = [('padronizador', padronizador), ('selecionador', selecionador),
          ('pca', pca), ('classificador', classificador)]
# Construindo o dicionário de hiperparâmetros
# HiperParametross otimizados com o pipeline podem ser identificados usando ‘__’ separando os nomes deles:
dic_de_hiperparametros = {
    # Aqui é uma hierarquia de metodos porque o selecionador é selectfrommodel
    # e os parametros são na verdade da árvore de decisão
    # estimator_ é um atributo de SelectFromModel
    'selecionador__estimator__min_samples_split':  uniform(loc=1e-6, scale=0.5), 
    'selecionador__estimator__min_samples_leaf':  uniform(loc=1e-6, scale=0.5),
    'selecionador__estimator__max_depth':  randint(1, 1000),
    'selecionador__estimator__criterion':  ['entropy', 'gini'],
    # Aqui é direto, temos pares da forma metodo__hiperparâmetro
    'pca__n_components': uniform(loc=0.5, scale=0.4999), # variância otimizada
    'classificador__hidden_layer_sizes': randint(1, 100),
    'classificador__learning_rate_init': expon(loc=1e-6, scale=0.1),
    'classificador__max_iter': randint(50, 1000),
    'classificador__momentum': uniform(loc=0.5, scale=0.4999)
}

# Pipeline
pipe = Pipeline(steps=etapas)

'''Preparando experimentos'''
orcamento = 20
# Busca aleatória com validação cruzada de 10 folds
random_search = RandomizedSearchCV(pipe, param_distributions=dic_de_hiperparametros,
                                   n_iter=orcamento, cv=10)
#seleção é com o conjunto de treinamento
random_search.fit(X_train, y_train)
# Este é o melhor pipeline, incluindo o classificador
# Toda instancia de teste vai passar por todo o pipeline
melhor_modelo = random_search.best_estimator_
# Esta é o melhor pipeline considerando todas as etapas
print(melhor_modelo)

"""**Testando o modelo com o conjunto de teste separado**"""

''' Testando com um conjunto de teste separado HOLDOUT'''
# Podemos usar a AUC da curva Precisão x cobertura
# Coletando predições
y_prob = melhor_modelo.predict_proba(X_test)[:, 1] # probabilidades para a 2a classe
y_pred = melhor_modelo.predict(X_test) # prediçoes discretas

# calculando a acuracia, precisao e cobertura
acuracia = accuracy_score(y_test, y_pred)
precisao = precision_score(y_test, y_pred)
cobertura = recall_score(y_test, y_pred)

# calculando a curva
curva_precisao, curva_cobertura, thresholds = precision_recall_curve(y_test, y_prob)

# calculando a área sob a curva
auc_precisao_cobertura = auc(curva_cobertura, curva_precisao)

print(classification_report(y_test, y_pred))
# imprimindo
print(f"Acurácia de teste = {acuracia}")
print(f"AUC = {auc_precisao_cobertura}")
print(f"Precisão = {precisao}, cobertura = {cobertura}")

''' Plotando curva '''
plt.plot(curva_cobertura, curva_precisao)
plt.show()

# Existe uma funçãão dedicada de plot da curva
# disp = plot_precision_recall_curve(classifier, X_test, y_test)
# disp.ax_.set_title('Binary class Precision-Recall curve: '
#                    'AP={0:0.2f}'.format(average_precision))

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import roc_curve

y_scores = cross_val_predict(melhor_modelo, X_train, y_train, cv = 10,)

fpr, tpr, thresholds = roc_curve(y_train, y_scores)
plt.plot(fpr, tpr, linewidth=2, label = "MPL")
plt.plot([0,1], [0,1], 'k--')
plt.axis([0, 1, 0, 1])
plt.xlabel('Taxa de Falsos Positivos')
plt.ylabel('Taxa de Verdadeiros Positivos')
plt.legend(loc = 'lower right')
plt.title('Curva ROC', fontsize = 14)
plt.show()